#!/usr/bin/env python

import time
import readline
import re
import getpass
import httplib2
import rdflib
import pynappl
import traceback
import StringIO
import optparse
from rdflib.graph import Graph
from rdflib.term import URIRef, BNode

from operator import itemgetter

class StatCollector(object):
  def __init__(self, storename, username, password, total_triples):
    self.storename = storename
    store_uri = "http://api.talis.com/stores/%s" % storename

    store = pynappl.Store(store_uri, username, password)

    self.store = store
    self.total_triples = total_triples
    self.triple_count = 0
    self.resource_count = 0
    self.literal_object_count = 0
    self.lang_literal_object_count = 0
    self.dt_literal_object_count = 0
    self.resource_object_count = 0
    self.class_queue = []
    self.resource_queue = []
    self.resources = {}
    self.classes = {}
    self.properties = {}
    self.g = Graph()
    self.uri_patterns = {}
    self.stores = {}
    self.languages = {}
    self.datatypes = {}

    self.internal_triples = 0
    self.interlinking_triples = 0
    self.external_triples = 0

  def add_uri_regex(self, regex, storename):
    if not storename in self.uri_patterns:
      self.uri_patterns[storename] = []
    self.uri_patterns[storename].append(regex)

  def probe(self):
    self.discover_types()
    self.get_sameas()
    while len(self.class_queue) > 0 or len(self.resource_queue) > 0:
      self.find_instances()
      self.describe_instances()
  
    self.analyse_instances()
    self.confirm_crosslinks()


  def discover_types(self):
    self.sample_type("SELECT ?s ?o WHERE {?s a ?o.} LIMIT 50")
      

  def sample_type(self, query):
    print query
    (response, body) = self.store.select(query)
    if response.status in range(200, 300):
      (headers, results) = body
      for result in results:
        if str(result['o']) not in self.classes:
          self.classes[str(result['o'])] = { 'occurrence': 0, 'properties' : {} }
          self.class_queue.append( str(result['o']) )
          query  = "SELECT ?s ?o WHERE {"
          query += "?s a ?o."
          for class_uri in self.classes:
            query += " FILTER (?o != <%s>)" % class_uri
          
          query += "} LIMIT 50"
          self.sample_type(query)

        if str(result['s']) not in self.resources:
          self.resources[str(result['s'])] = { }
          self.resource_queue.append( str(result['s']) )
  
  

  def find_instances(self):
    for class_uri in self.class_queue:
      query = "SELECT ?s WHERE {?s a <%s> . } LIMIT 50" % class_uri
      print query

      (response, body) = self.store.select(query)
      if response.status in range(200, 300):
        (headers, results) = body
        for result in results:
          if str(result['s']) not in self.resources:
            self.resources[str(result['s'])] = { }
            self.resource_queue.append( str(result['s']) )

    self.class_queue = []

  def get_sameas(self):
    query = "SELECT ?s ?o WHERE {?s <http://www.w3.org/2002/07/owl#sameAs> ?o . } LIMIT 50"
    print query

    (response, body) = self.store.select(query)
    if response.status in range(200, 300):
      (headers, results) = body
      for result in results:
        if str(result['s']) not in self.resources:
          self.resources[str(result['s'])] = { }
          self.resource_queue.append( str(result['s']) )
        if str(result['o']) not in self.resources:
          self.resources[str(result['o'])] = { }
          self.resource_queue.append( str(result['o']) )


  def describe_instances(self):
    for u in self.resource_queue:
      query = "CONSTRUCT { <%s> ?p1 ?o . ?s ?p2 <%s> } {<%s> ?p1 ?o . OPTIONAL { ?s ?p2 <%s> FILTER (?p2 != <http://www.w3.org/1999/02/22-rdf-syntax-ns#type>)} }" % (u, u, u, u)
      print query
      (response, body) = self.store.sparql(query)
      if response.status in range(200, 300):
        self.resource_count += 1
        self.g.parse(StringIO.StringIO(body))

    self.resource_queue = []

  def analyse_instances(self):
    for (s, p, o) in self.g.triples((None, None, None)):
      self.triple_count += 1
      if p not in self.properties:
        self.properties[p] = { 'occurrence' : 1 }
      else:
        self.properties[p]['occurrence'] += 1

      subject_stores = self.find_stores(str(s))
      for storename in subject_stores:
        if storename != self.storename:
          if storename not in self.stores:
            self.stores[storename] = { 'occurrence' : 1, 'subjects' : [str(s)], 'objects' : [], 'confirmed_subjects' : [], 'confirmed_objects' : [] }
          else:
            self.stores[storename]['occurrence'] += 1
            if str(s) not in self.stores[storename]['subjects']:
              self.stores[storename]['subjects'].append(str(s))

      if str(p) == "http://www.w3.org/1999/02/22-rdf-syntax-ns#type":
        if str(o) not in self.classes:
          self.classes[str(o)] = { 'occurrence':1, 'properties' : {}}
          self.class_queue.append( str(o) )
        else:
          self.classes[str(o)]['occurrence'] += 1
      else:
        if isinstance(o, rdflib.term.URIRef):
          self.resource_object_count += 1
          object_stores = self.find_stores(str(o))
          for storename in object_stores:
            if storename != self.storename:
              if storename not in self.stores:
                self.stores[storename] = { 'occurrence' : 1, 'subjects' : [], 'objects' : [str(o)], 'confirmed_subjects' : [], 'confirmed_objects' : [] }
              else:
                self.stores[storename]['occurrence'] += 1
                if str(o) not in self.stores[storename]['objects']:
                  self.stores[storename]['objects'].append(str(o))
                  
          if self.storename in object_stores:
            if self.storename in subject_stores:
              self.internal_triples += 1
            else:
              self.interlinking_triples += 1
          else:
            if self.storename in subject_stores:
              self.interlinking_triples += 1
            else:
              self.external_triples += 1
              
        else:
          self.literal_object_count += 1
          if o.language:
            self.lang_literal_object_count += 1
            if o.language not in self.languages:
              self.languages[o.language] = 1
            else:
              self.languages[o.language] += 1
          if o.datatype:
            self.dt_literal_object_count += 1
            if o.datatype not in self.datatypes:
              self.datatypes[o.datatype] = 1
            else:
              self.datatypes[o.datatype] += 1
        
          if self.storename in subject_stores:
            self.internal_triples += 1
          else:
            self.external_triples += 1

    for class_uri in self.classes:
      properties = {}
      
      for (s, p, o) in self.g.triples((None, URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), URIRef(class_uri))):
        for (s1, p1, o1) in self.g.triples((s, None, None)):
          if str(p1) != "http://www.w3.org/1999/02/22-rdf-syntax-ns#type":
            if str(p1) not in properties:
              properties[str(p1)] = 1
            else:
              properties[str(p1)] += 1
              
      self.classes[class_uri]['properties'] = properties
    
    
  def find_stores(self, uri):
    matching_stores = []
    for storename in self.uri_patterns:
      for pattern in self.uri_patterns[storename]:
          if re.search(pattern, uri):
            matching_stores.append(storename)
    
    return matching_stores

  
  def confirm_crosslinks(self):
    for storename in self.stores:
      conf_store = pynappl.Store("http://api.talis.com/stores/%s" % storename)
      for resource in self.stores[storename]['subjects']:
        query = "ASK WHERE {<%s> ?p ?o . }" % resource
        print query

        (response, body) = conf_store.ask(query)
        if response.status in range(200, 300):
          if body:
            self.stores[storename]['confirmed_subjects'].append(resource)
    
      for resource in self.stores[storename]['objects']:
        query = "ASK WHERE {<%s> ?p ?o . }" % resource
        print query

        (response, body) = conf_store.ask(query)
        if response.status in range(200, 300):
          if body:
            self.stores[storename]['confirmed_objects'].append(resource)

  def report(self):


    r = '';
    r +=  "SAMPLE INFORMATION\n"
    r +=  "------------------\n"
    r +=  "Store analysed: %s\n" % self.storename
    r +=  "Total resources analysed: %s\n" % self.resource_count
    r +=  "Total triples analysed: %s\n" % self.triple_count

    r +=  "\n"
    r +=  "GENERAL STATISTICS\n"
    r +=  "------------------\n"
    if self.resource_count > 0:
      r +=  "Average triples per resource: %1.2f\n" % ((1.0 * self.triple_count) / self.resource_count)
      
    r +=  "%s (%1.2f%%) triple objects were resources, %s (%1.2f%%) were literals\n" % (self.resource_object_count, 100.0 * self.resource_object_count / (self.resource_object_count + self.literal_object_count), self.literal_object_count, 100.0 * self.literal_object_count / (self.resource_object_count + self.literal_object_count) )
      
      
    
    r +=  "%s (%1.2f%%) literals had languages\n" % (self.lang_literal_object_count, 100.0 * self.lang_literal_object_count / self.literal_object_count)
    if len(self.languages.keys()) > 0:
      r +=  "%s different languages were found:\n" % (len(self.languages.keys()))
      for language in self.languages:
        r +=  "  %s (%s triples)\n" % (language, self.languages[language])

    r +=  "%s (%1.2f%%) literals had datatypes\n" % (self.dt_literal_object_count, 100.0 * self.dt_literal_object_count / self.literal_object_count)
    if len(self.datatypes.keys()) > 0:
      r +=  "%s different datatypes were found:\n" % (len(self.datatypes.keys()))
      for datatype in self.datatypes:
        r +=  "  %s (%s triples)\n" % (datatype, self.datatypes[datatype])


    r +=  "\n"
    r +=  "VOCABULARY USAGE\n"
    r +=  "----------------\n"
    r +=  "The following %s classes were found in use\n" % (len(self.classes.keys()))
    for class_uri in self.classes:
      r +=  "  %s (%s triples)\n" % (class_uri, self.classes[class_uri]['occurrence'])

    r +=  "\n"
    r +=  "The following %s properties were found in use\n" % (len(self.properties.keys()))
    for property_uri in self.properties:
      r +=  "  %s (%s triples)\n" % (property_uri, self.properties[property_uri]['occurrence'])


    r += "\n"

    for class_uri in self.classes:
      if (len(self.classes[class_uri]['properties']) > 0):
        r += "\nProperties commonly used with class %s\n" % class_uri
        for property_uri in sorted(self.classes[class_uri]['properties'], key=self.classes[class_uri]['properties'].get, reverse=True):
          r += "  %s (%s occurrences)\n" % (property_uri, self.classes[class_uri]['properties'][property_uri])


    r +=  "\n"
    r +=  "INTERLINKING\n"
    r +=  "------------\n"
    
    r += "The following URI patterns were assumed for this store:\n"
    for pattern in self.uri_patterns[self.storename]:
      r += pattern + "\n"
    
    r += "\n"  
    r += "%s (%1.2f%%) triples were deemed to be internal (only referring to resources in this dataset)\n" % (self.internal_triples, 100.0 * self.internal_triples / self.triple_count )  
    r += "%s (%1.2f%%) triples were deemed to be external (only referring to resources outside this dataset)\n" % (self.external_triples, 100.0 * self.external_triples / self.triple_count )  
    r += "%s (%1.2f%%) triples were deemed to be interlinking (one resource in this dataset, one outside)\n" % (self.interlinking_triples, 100.0 * self.interlinking_triples / self.triple_count )
    r += "\n"  

    for storename in self.stores:
      r +=  "Interlinks to '%s' store\n" % (storename)
      
      r +=  "  Found %s triples (%1.2f%%) that potentially referenced data held in '%s' store:\n" % (self.stores[storename]['occurrence'], 100.0 * self.stores[storename]['occurrence'] / self.triple_count,  storename)

      r +=  "\n"
      if len(self.stores[storename]['subjects']) > 0:
        r +=  "  %s references in the subject position, of which %s (%1.2f%%) actually had descriptions in the '%s' store:\n" % (len(self.stores[storename]['subjects']), len(self.stores[storename]['confirmed_subjects']), 100.0 * len(self.stores[storename]['confirmed_subjects']) / len(self.stores[storename]['subjects']), storename)
        for uri in self.stores[storename]['confirmed_subjects']:
          r +=  "    %s\n" % uri

      r +=  "\n"
      if len(self.stores[storename]['objects']) > 0:
        r +=  "  %s references in the object position, of which %s (%1.2f%%) actually had descriptions in the '%s' store:\n" % (len(self.stores[storename]['objects']), len(self.stores[storename]['confirmed_objects']), 100.0 * len(self.stores[storename]['confirmed_objects']) / len(self.stores[storename]['objects']), storename)
        for uri in self.stores[storename]['confirmed_objects']:
          r +=  "    %s\n" % uri

      r +=  "\n"
    
    
    report_out = open('%s' % self.storename, 'w')
    report_out.write(r)
    report_out.close()
    print r


def main():
  p = optparse.OptionParser()
  p.add_option("-u", "--username", action="store", dest="username", metavar="USERNAME", help="login in as USERNAME")
  p.add_option("-p", "--password", action="store", dest="password", metavar="PASSWORD", help="login in with PASSWORD")
  p.add_option("-s", "--storename", action="store", dest="storename", metavar="STORENAME", help="name of store")
  opts, args = p.parse_args()

  
  s = StatCollector(opts.storename, opts.username, opts.password, 500000000)


  s.add_uri_regex('^http://semanticlibrary.org/', 'semlib-dev1')
  s.add_uri_regex('^http://iandavis.com/id/', 'iand')
  s.add_uri_regex('^http://dbpedia.org/resource/', 'dbpedia')
  s.add_uri_regex('^http://musicbrainz.dataincubator.org/', 'musicbrainz')
  s.add_uri_regex('^http://discogs.dataincubator.org/', 'discogs')
  s.add_uri_regex('^http://pokedex.dataincubator.org/', 'pokedex') 
  s.add_uri_regex('^http://nasa.dataincubator.org/', 'space')
  s.add_uri_regex('^http://openlibrary.org/', 'openlibrary')
  s.add_uri_regex('^http://www.johngoodwin.me.uk/family/', 'jgoodwin-genealogy')
  s.add_uri_regex('^http://ons.dataincubator.org/', 'ons')
  s.add_uri_regex('^http://periodicals.dataincubator.org/', 'periodicals')
  s.add_uri_regex('^http://oecd.dataincubator.org/', 'iand-dev1')
  s.add_uri_regex('^http://climb.dataincubator.org/', 'kwijibo-dev2')
  s.add_uri_regex('^http://www.bbc.co.uk/programmes/', 'bbc-backstage')
  s.add_uri_regex('^http://www.bbc.co.uk/music/', 'bbc-backstage')
  s.add_uri_regex('^http://www.bbc.co.uk/nature/', 'bbc-wildlife')
  s.add_uri_regex('^http://lcsubjects.org/', 'lcsh-info')
  s.add_uri_regex('^http://lists.broadminsteruniversity.org/', 'zephyr-live-broadminster3')
  s.add_uri_regex('^http://ckan.net/', 'ckan')
  s.add_uri_regex('^http://moseley.dataincubator.org/', 'moseley')
  s.add_uri_regex('^http://airports.dataincubator.org/', 'airports')
  s.add_uri_regex('^http://data.ordnancesurvey.co.uk/', 'ordnance-survey')
  s.add_uri_regex('^http://bl.dataincubator.org/', 'bl-dev1')
  s.add_uri_regex('^http://analytics.data.gov.uk/', 'govuk-analytics')
  s.add_uri_regex('^http://business.data.gov.uk/', 'govuk-business')
  s.add_uri_regex('^http://crime.data.gov.uk/', 'govuk-crime')
  s.add_uri_regex('^http://culture.data.gov.uk/', 'govuk-culture')
  s.add_uri_regex('^http://datasets.data.gov.uk/', 'govuk-datasets')
  s.add_uri_regex('^http://statistics.data.gov.uk/', 'govuk-statistics')
  s.add_uri_regex('^http://statistics.data.gov.uk/', 'govuk-education')
  s.add_uri_regex('^http://economy.data.gov.uk/', 'govuk-economy')
  s.add_uri_regex('^http://education.data.gov.uk/', 'govuk-education')
  s.add_uri_regex('^http://finance.data.gov.uk/', 'govuk-finance')
  s.add_uri_regex('^http://geo.data.gov.uk/', 'govuk-geo')
  s.add_uri_regex('^http://health.data.gov.uk/', 'govuk-health')
  s.add_uri_regex('^http://international-aid.data.gov.uk/', 'govuk-international-aid')
  s.add_uri_regex('^http://justice.data.gov.uk/', 'govuk-justice')
  s.add_uri_regex('^http://legislation.data.gov.uk/', 'govuk-legislation')
  s.add_uri_regex('^http://transport.data.gov.uk/', 'transport')
  s.add_uri_regex('^http://local-government.data.gov.uk/', 'govuk-local-government')
  s.add_uri_regex('^http://notices.data.gov.uk/', 'govuk-notices')
  s.add_uri_regex('^http://people.data.gov.uk/', 'govuk-people')
  s.add_uri_regex('^http://science.data.gov.uk/', 'govuk-science')
  s.add_uri_regex('^http://data.nytimes.com/', 'nytimes')

  s.add_uri_regex('^http://sws.geonames.org/', 'geonames')

  s.add_uri_regex('^http://purl.org/vocabularies/princeton/wn30/', 'wordnet')
  s.add_uri_regex('^http://linkedgeodata.org/', 'linkedgeodata')

  s.add_uri_regex('^http://api.talis.com/stores/engagetenant18/items', 'engagetenant18')

  s.add_uri_regex('^http://www.london-gazette.co.uk/', 'datagovuk')
  s.add_uri_regex('^http://www.gazettes-online.co.uk/', 'datagovuk') 
  s.add_uri_regex('^http://guardian.dataincubator.org/', 'guardian')

  s.add_uri_regex('^http://www4.wiwiss.fu-berlin.de/factbook/resource/', 'cia-factbook')

  s.add_uri_regex('^http://kierdavis.com/', 'kier-dev3')
  s.add_uri_regex('^http://open.vocab.org/terms', 'openvocab')
  s.add_uri_regex('^http://purl.org/dc/', 'schema-cache')
  s.add_uri_regex('^http://purl.org/goodrelations/v1#', 'schema-cache')
  s.add_uri_regex('^http://purl.org/ontology/mo/', 'schema-cache')
  s.add_uri_regex('^http://purl.org/vocab/', 'schema-cache')
  s.add_uri_regex('^http://www.w3.org/2002/07/owl#', 'schema-cache')
  s.add_uri_regex('^http://www.w3.org/2004/02/skos/core#', 'schema-cache')
  s.add_uri_regex('^http://xmlns.com/foaf/0.1/', 'schema-cache')
  s.add_uri_regex('^http://www.w3.org/2004/02/skos/core#', 'schema-cache')
  s.add_uri_regex('^http://purl.org/goodrelations/v1#', 'schema-cache')
#  s.add_uri_regex('^http://uberblic.org/resource/', 'uberblic')
  s.add_uri_regex('^http://purl.org/NET/lccn/', 'rsinger-dev4')
  s.add_uri_regex('^http://iandavis.com/orlanth', 'iand-dev5')
  s.add_uri_regex('^http://example.com/chow', 'orlanth-data1')
  s.add_uri_regex('^http://dbpedia.org/resource', 'near')
  s.add_uri_regex('^http://rdfize.com/geo/', 'near')
  s.add_uri_regex('^http://education.data.gov.uk/id/', 'near')
  s.add_uri_regex('^http://transport.data.gov.uk/id/', 'near')
  s.add_uri_regex('^http://products.semweb.bestbuy.com', 'orlanth-data9')





  s.probe()
  s.report()

if __name__ == "__main__":
  main()
